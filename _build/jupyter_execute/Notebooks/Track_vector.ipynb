{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we read in the Master XML file made using NapaTrackMater and create N, Delta times Attribute dimensional vectors. N being the number of tracks present in the chosen region, R, Delta being the chosen time interval (t_minus + t_plus) {t - t_minus, t + t_plus} and Attributes being the morphological and the dynamic properties associated with cells in the tracks. We concatenate the Attribute componenets over the chosen time interval to create a Delta times Attribute dimensional vector and create a pandas dataframe with these vectors for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:08:24.729227: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:08:25.358781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kapoorlabs_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgui\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqt5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnapatrackmater\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTrackvector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrackVector\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interactive, widgets\n",
      "File \u001b[0;32m~/anaconda3/envs/naparienv/lib/python3.10/site-packages/napatrackmater/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_model, register_aliases, clear_models_and_aliases\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Clustering\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDeepEmbeddedClustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepEmbeddedClustering\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCloudAutoEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CloudAutoEncoder\n",
      "File \u001b[0;32m~/anaconda3/envs/naparienv/lib/python3.10/site-packages/napatrackmater/clustering.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkapoorlabs_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightning_trainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoLightningModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcellshape_helper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvendor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_geometric_files\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_off, sample_points\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kapoorlabs_lightning'"
     ]
    }
   ],
   "source": [
    "%gui qt5\n",
    "from napatrackmater.Trackvector import TrackVector\n",
    "from pathlib import Path\n",
    "from ipywidgets import interactive, widgets\n",
    "from IPython.display import display\n",
    "import napari \n",
    "from tifffile import imread\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_xml_path = Path('C:/Users/rando/Downloads/Mari_project/master_test_tracks.xml')\n",
    "spot_csv_path = Path('C:/Users/rando/Downloads/Mari_project/test_spots.csv')\n",
    "track_csv_path = Path('C:/Users/rando/Downloads/Mari_project/test_tracks.csv')\n",
    "edges_csv_path = Path('C:/Users/rando/Downloads/Mari_project/test_edges.csv')\n",
    "show_tracks = False\n",
    "base_dir = 'C:/Users/rando/Downloads/Mari_project/'\n",
    "plot_data_save_name = 'test_plot_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_tracks:\n",
    "  viewer = napari.Viewer()\n",
    "  image = imread('C:/Users/rando/Downloads/Mari_project/gt/rawk.tif')\n",
    "\n",
    "else:\n",
    "    viewer = None\n",
    "    image = None\n",
    "track_vectors = TrackVector(viewer,image,master_xml_path,spot_csv_path, track_csv_path, edges_csv_path, show_tracks = show_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_setter(deltat, deltax, deltay):\n",
    "    track_vectors.t_minus = deltat[0]\n",
    "    track_vectors.t_plus = deltat[-1]\n",
    "    \n",
    "    track_vectors.x_start = deltax[0]\n",
    "    track_vectors.x_end = deltax[-1]\n",
    "    \n",
    "    track_vectors.y_start = deltay[0]\n",
    "    track_vectors.y_end = deltay[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vectors(vector_dicts, cluster_labels, base_dir):\n",
    "    print(f'Number of clusters: {max(cluster_labels)}')\n",
    "    t_min = min(vector['t'] for vector in vector_dicts)\n",
    "    t_max = max(vector['t'] for vector in vector_dicts)\n",
    "    y_min = min(vector['y'] for vector in vector_dicts)\n",
    "    y_max = max(vector['y'] for vector in vector_dicts)\n",
    "    x_min = min(vector['x'] for vector in vector_dicts)\n",
    "    x_max = max(vector['x'] for vector in vector_dicts)\n",
    "\n",
    "    t_step = 1\n",
    "    y_step = 10\n",
    "    x_step = 10\n",
    "\n",
    "    t_grid = np.arange(t_min, t_max + t_step, t_step)\n",
    "    y_grid = np.arange(y_min, y_max + y_step, y_step)\n",
    "    x_grid = np.arange(x_min, x_max + x_step, x_step)\n",
    "\n",
    "    cluster_grid = np.zeros((len(t_grid), len(y_grid), len(x_grid)))\n",
    "\n",
    "    for i, vector in enumerate(vector_dicts):\n",
    "        t_index = int((vector['t'] - t_min) / t_step)\n",
    "        y_index = int((vector['y'] - y_min) / y_step)\n",
    "        x_index = int((vector['x'] - x_min) / x_step)\n",
    "        cluster_label = cluster_labels[i]  \n",
    "        cluster_grid[t_index, y_index, x_index] = cluster_label\n",
    "\n",
    "    # Create a colormap for clusters (use 'jet' colormap)\n",
    "    cmap = plt.get_cmap('jet', max(cluster_labels) + 1)  # Adding 1 for potential 0-based labels\n",
    "\n",
    "    # Create a 3D figure and axes\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Define a list of unique cluster labels\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "\n",
    "    markers = ['o', 's', '^', 'D', 'v', 'P']  # Customize marker styles as needed\n",
    "\n",
    "    for cluster_label in unique_clusters:\n",
    "        # Find indices of vectors in the current cluster\n",
    "        cluster_indices = np.where(cluster_labels == cluster_label)[0]\n",
    "        t_values = [vector_dicts[i]['t'] for i in cluster_indices]\n",
    "        y_values = [vector_dicts[i]['y'] for i in cluster_indices]\n",
    "        x_values = [vector_dicts[i]['x'] for i in cluster_indices]\n",
    "        color = cmap(cluster_label)  # Use cluster_label as color index\n",
    "        marker = markers[cluster_label % len(markers)]  # Cycle through markers\n",
    "        ax.scatter(t_values, y_values, x_values, c=color, label=f'Cluster {cluster_label}', marker=marker)\n",
    "\n",
    "    ax.set_xlabel('Time (t)')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "    ax.set_zlabel('X Coordinate')\n",
    "    ax.legend()  # Add legend\n",
    "\n",
    "    # Customize plot title, labels, aspect ratio, etc. as needed\n",
    "\n",
    "    plt.show()\n",
    "    t_values = []\n",
    "    y_values = []\n",
    "    x_values = []\n",
    "    cluster_label_values = []\n",
    "\n",
    "    for i, vector in enumerate(vector_dicts):\n",
    "        t_values.append(vector['t'])\n",
    "        y_values.append(vector['y'])\n",
    "        x_values.append(vector['x'])\n",
    "        cluster_label_values.append(cluster_labels[i])\n",
    "\n",
    "    \n",
    "    plot_data = pd.DataFrame({\n",
    "        't': t_values,\n",
    "        'y': y_values,\n",
    "        'x': x_values,\n",
    "        'cluster_label': cluster_label_values\n",
    "    })\n",
    "    csv_file_path = os.path.join(base_dir, plot_data_save_name + '_clusters.csv')\n",
    "    plot_data.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "\n",
    "def recreate_plot_from_csv(csv_path):\n",
    "    # Load the CSV file containing the plot data\n",
    "    plot_data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract data from the CSV\n",
    "    t_values = plot_data['t']\n",
    "    y_values = plot_data['y']\n",
    "    x_values = plot_data['x']\n",
    "    cluster_labels = plot_data['cluster_label']\n",
    "\n",
    "    # Create the 3D plot using the loaded data\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    cmap = plt.get_cmap('tab20', max(cluster_labels))\n",
    "    for cluster_label in unique_clusters:\n",
    "        cluster_indices = np.where(cluster_labels == cluster_label)[0]\n",
    "        t_cluster = [t_values[i] for i in cluster_indices]\n",
    "        y_cluster = [y_values[i] for i in cluster_indices]\n",
    "        x_cluster = [x_values[i] for i in cluster_indices]\n",
    "        color = cmap(cluster_label - 1)\n",
    "        ax.scatter(t_cluster, y_cluster, x_cluster, c=color, label=f'Cluster {cluster_label}', marker='o')\n",
    "\n",
    "    ax.set_xlabel('Time (t)')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "    ax.set_zlabel('X Coordinate')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "def cosine_similarity_without_tzyx(vector1, vector2):\n",
    "    vector1 = vector1[6:]\n",
    "    vector2 = vector2[6:]\n",
    "\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_a = np.linalg.norm(vector1)\n",
    "    norm_b = np.linalg.norm(vector2)\n",
    "    \n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0  \n",
    "    \n",
    "    return 1.0 - dot_product / (norm_a * norm_b)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_vector_widgets = interactive(track_setter, deltat = widgets.IntRangeSlider(\n",
    "    value=[track_vectors.tstart, track_vectors.tend],\n",
    "    min= track_vectors.tstart,\n",
    "    max=track_vectors.tend,\n",
    "    step=1,\n",
    "    description='Delta Time',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "), \n",
    "    deltax = widgets.IntRangeSlider(\n",
    "    value=[track_vectors.xmin, track_vectors.xmax],\n",
    "    min= track_vectors.xmin,\n",
    "    max=track_vectors.xmax,\n",
    "    step=1,\n",
    "    description='Delta X',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "), \n",
    "    deltay = widgets.IntRangeSlider(\n",
    "    value=[track_vectors.ymin, track_vectors.ymax],\n",
    "    min= track_vectors.ymin,\n",
    "    max=track_vectors.ymax,\n",
    "    step=1,\n",
    "    description='Delta Y',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "),                               \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "track_vector_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_vectors._interactive_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_shape_dynamic_vectors = track_vectors.current_shape_dynamic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_shape_dynamic_dataframe = []\n",
    "for i in range(len(current_shape_dynamic_vectors)):\n",
    "   \n",
    "   vector_list = list(zip(current_shape_dynamic_vectors[i]))\n",
    "   data_frame_list = np.transpose(np.asarray([vector_list[i] for i in range(len(vector_list))])[:,0,:]) \n",
    "   \n",
    "   shape_dynamic_dataframe = pd.DataFrame(data_frame_list, columns =['Track ID', 't', 'z', 'y', 'x', 'Dividing', 'Number_Dividing',  'Radius', 'Volume', 'Eccentricity Comp First', 'Eccentricity Comp Second', 'Surface Area', 'Speed', 'Motion_Angle', 'Acceleration', 'Distance_Cell_mask', 'Radial_Angle', 'Cell_Axis_Mask'])\n",
    "   if len(global_shape_dynamic_dataframe) == 0:\n",
    "        global_shape_dynamic_dataframe = shape_dynamic_dataframe\n",
    "   else:\n",
    "        global_shape_dynamic_dataframe = pd.concat([global_shape_dynamic_dataframe, shape_dynamic_dataframe],ignore_index=True)\n",
    "\n",
    "global_shape_dynamic_dataframe = global_shape_dynamic_dataframe.set_index('Track ID')\n",
    "global_shape_dynamic_dataframe = global_shape_dynamic_dataframe.sort_values(by=['Track ID'])\n",
    "global_shape_dynamic_dataframe = global_shape_dynamic_dataframe.sort_values(by=['t'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_vectors = {}\n",
    "\n",
    "unique_track_ids = global_shape_dynamic_dataframe['Track ID'].unique()\n",
    "for track_id in unique_track_ids:\n",
    "    track_data = global_shape_dynamic_dataframe[global_shape_dynamic_dataframe['Track ID'] == track_id].sort_values(by='t')\n",
    "    \n",
    "    track_vector = track_data[['t', 'z', 'y', 'x', 'Dividing', 'Number_Dividing', 'Radius', 'Volume', 'Eccentricity Comp First', 'Eccentricity Comp Second', 'Surface Area', 'Speed', 'Motion_Angle', 'Acceleration', 'Distance_Cell_mask', 'Radial_Angle', 'Cell_Axis_Mask']]\n",
    "    \n",
    "    track_vector_list = track_vector.to_dict(orient='records')\n",
    "    \n",
    "    analysis_vectors[track_id] = track_vector_list\n",
    "\n",
    "vector_dicts = [analysis_vectors[key][0] for key in analysis_vectors]\n",
    "vector_array = np.array([list(vector.values()) for vector in vector_dicts])\n",
    "\n",
    "cosine_distance = pdist(vector_array, metric=cosine_similarity_without_tzyx)\n",
    "\n",
    "linkage_matrix = linkage(cosine_distance, method='average')\n",
    "\n",
    "threshold = 0.02  \n",
    "\n",
    "cluster_labels = fcluster(linkage_matrix, threshold, criterion='distance')\n",
    "    \n",
    "plot_vectors(vector_dicts, cluster_labels, base_dir)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naparienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}