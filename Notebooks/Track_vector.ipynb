{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we read in the Master XML file made using NapaTrackMater and create N, Delta times Attribute dimensional vectors. N being the number of tracks present in the chosen region, R, Delta being the chosen time interval (t_minus + t_plus) {t - t_minus, t + t_plus} and Attributes being the morphological and the dynamic properties associated with cells in the tracks. We concatenate the Attribute componenets over the chosen time interval to create a Delta times Attribute dimensional vector and create a pandas dataframe with these vectors for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt5\n",
    "from napatrackmater.Trackvector import TrackVector\n",
    "from pathlib import Path\n",
    "from ipywidgets import interactive, widgets\n",
    "from IPython.display import display\n",
    "import napari \n",
    "from tifffile import imread\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_xml_path = Path('C:/Users/rando/Downloads/Mari_project/master_test_tracks.xml')\n",
    "spot_csv_path = Path('C:/Users/rando/Downloads/Mari_project/test_spots.csv')\n",
    "track_csv_path = Path('C:/Users/rando/Downloads/Mari_project/test_tracks.csv')\n",
    "edges_csv_path = Path('C:/Users/rando/Downloads/Mari_project/test_edges.csv')\n",
    "show_tracks = False\n",
    "base_dir = 'C:/Users/rando/Downloads/Mari_project/'\n",
    "plot_data_save_name = 'test_plot_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_tracks:\n",
    "  viewer = napari.Viewer()\n",
    "  image = imread('C:/Users/rando/Downloads/Mari_project/gt/rawk.tif')\n",
    "\n",
    "else:\n",
    "    viewer = None\n",
    "    image = None\n",
    "track_vectors = TrackVector(viewer,image,master_xml_path,spot_csv_path, track_csv_path, edges_csv_path, show_tracks = show_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_setter(deltat, deltax, deltay):\n",
    "    track_vectors.t_minus = deltat[0]\n",
    "    track_vectors.t_plus = deltat[-1]\n",
    "    \n",
    "    track_vectors.x_start = deltax[0]\n",
    "    track_vectors.x_end = deltax[-1]\n",
    "    \n",
    "    track_vectors.y_start = deltay[0]\n",
    "    track_vectors.y_end = deltay[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vectors(vector_dicts, cluster_labels, base_dir):\n",
    "    print(f'Number of clusters: {max(cluster_labels)}')\n",
    "    t_min = min(vector['t'] for vector in vector_dicts)\n",
    "    t_max = max(vector['t'] for vector in vector_dicts)\n",
    "    y_min = min(vector['y'] for vector in vector_dicts)\n",
    "    y_max = max(vector['y'] for vector in vector_dicts)\n",
    "    x_min = min(vector['x'] for vector in vector_dicts)\n",
    "    x_max = max(vector['x'] for vector in vector_dicts)\n",
    "\n",
    "    t_step = 1\n",
    "    y_step = 10\n",
    "    x_step = 10\n",
    "\n",
    "    t_grid = np.arange(t_min, t_max + t_step, t_step)\n",
    "    y_grid = np.arange(y_min, y_max + y_step, y_step)\n",
    "    x_grid = np.arange(x_min, x_max + x_step, x_step)\n",
    "\n",
    "    cluster_grid = np.zeros((len(t_grid), len(y_grid), len(x_grid)))\n",
    "\n",
    "    for i, vector in enumerate(vector_dicts):\n",
    "        t_index = int((vector['t'] - t_min) / t_step)\n",
    "        y_index = int((vector['y'] - y_min) / y_step)\n",
    "        x_index = int((vector['x'] - x_min) / x_step)\n",
    "        cluster_label = cluster_labels[i]  \n",
    "        cluster_grid[t_index, y_index, x_index] = cluster_label\n",
    "\n",
    "    # Create a colormap for clusters (use 'jet' colormap)\n",
    "    cmap = plt.get_cmap('jet', max(cluster_labels) + 1)  # Adding 1 for potential 0-based labels\n",
    "\n",
    "    # Create a 3D figure and axes\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Define a list of unique cluster labels\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "\n",
    "    markers = ['o', 's', '^', 'D', 'v', 'P']  # Customize marker styles as needed\n",
    "\n",
    "    for cluster_label in unique_clusters:\n",
    "        # Find indices of vectors in the current cluster\n",
    "        cluster_indices = np.where(cluster_labels == cluster_label)[0]\n",
    "        t_values = [vector_dicts[i]['t'] for i in cluster_indices]\n",
    "        y_values = [vector_dicts[i]['y'] for i in cluster_indices]\n",
    "        x_values = [vector_dicts[i]['x'] for i in cluster_indices]\n",
    "        color = cmap(cluster_label)  # Use cluster_label as color index\n",
    "        marker = markers[cluster_label % len(markers)]  # Cycle through markers\n",
    "        ax.scatter(t_values, y_values, x_values, c=color, label=f'Cluster {cluster_label}', marker=marker)\n",
    "\n",
    "    ax.set_xlabel('Time (t)')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "    ax.set_zlabel('X Coordinate')\n",
    "    ax.legend()  # Add legend\n",
    "\n",
    "    # Customize plot title, labels, aspect ratio, etc. as needed\n",
    "\n",
    "    plt.show()\n",
    "    t_values = []\n",
    "    y_values = []\n",
    "    x_values = []\n",
    "    cluster_label_values = []\n",
    "\n",
    "    for i, vector in enumerate(vector_dicts):\n",
    "        t_values.append(vector['t'])\n",
    "        y_values.append(vector['y'])\n",
    "        x_values.append(vector['x'])\n",
    "        cluster_label_values.append(cluster_labels[i])\n",
    "\n",
    "    \n",
    "    plot_data = pd.DataFrame({\n",
    "        't': t_values,\n",
    "        'y': y_values,\n",
    "        'x': x_values,\n",
    "        'cluster_label': cluster_label_values\n",
    "    })\n",
    "    csv_file_path = os.path.join(base_dir, plot_data_save_name + '_clusters.csv')\n",
    "    plot_data.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "\n",
    "def recreate_plot_from_csv(csv_path):\n",
    "    # Load the CSV file containing the plot data\n",
    "    plot_data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract data from the CSV\n",
    "    t_values = plot_data['t']\n",
    "    y_values = plot_data['y']\n",
    "    x_values = plot_data['x']\n",
    "    cluster_labels = plot_data['cluster_label']\n",
    "\n",
    "    # Create the 3D plot using the loaded data\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    cmap = plt.get_cmap('tab20', max(cluster_labels))\n",
    "    for cluster_label in unique_clusters:\n",
    "        cluster_indices = np.where(cluster_labels == cluster_label)[0]\n",
    "        t_cluster = [t_values[i] for i in cluster_indices]\n",
    "        y_cluster = [y_values[i] for i in cluster_indices]\n",
    "        x_cluster = [x_values[i] for i in cluster_indices]\n",
    "        color = cmap(cluster_label - 1)\n",
    "        ax.scatter(t_cluster, y_cluster, x_cluster, c=color, label=f'Cluster {cluster_label}', marker='o')\n",
    "\n",
    "    ax.set_xlabel('Time (t)')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "    ax.set_zlabel('X Coordinate')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "def cosine_similarity_without_tzyx(vector1, vector2):\n",
    "    vector1 = vector1[6:]\n",
    "    vector2 = vector2[6:]\n",
    "\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_a = np.linalg.norm(vector1)\n",
    "    norm_b = np.linalg.norm(vector2)\n",
    "    \n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0  \n",
    "    \n",
    "    return 1.0 - dot_product / (norm_a * norm_b)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_vector_widgets = interactive(track_setter, deltat = widgets.IntRangeSlider(\n",
    "    value=[track_vectors.tstart, track_vectors.tend],\n",
    "    min= track_vectors.tstart,\n",
    "    max=track_vectors.tend,\n",
    "    step=1,\n",
    "    description='Delta Time',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "), \n",
    "    deltax = widgets.IntRangeSlider(\n",
    "    value=[track_vectors.xmin, track_vectors.xmax],\n",
    "    min= track_vectors.xmin,\n",
    "    max=track_vectors.xmax,\n",
    "    step=1,\n",
    "    description='Delta X',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "), \n",
    "    deltay = widgets.IntRangeSlider(\n",
    "    value=[track_vectors.ymin, track_vectors.ymax],\n",
    "    min= track_vectors.ymin,\n",
    "    max=track_vectors.ymax,\n",
    "    step=1,\n",
    "    description='Delta Y',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "),                               \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "track_vector_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_vectors._interactive_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_shape_dynamic_vectors = track_vectors.current_shape_dynamic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_shape_dynamic_dataframe = []\n",
    "for i in range(len(current_shape_dynamic_vectors)):\n",
    "   \n",
    "   vector_list = list(zip(current_shape_dynamic_vectors[i]))\n",
    "   data_frame_list = np.transpose(np.asarray([vector_list[i] for i in range(len(vector_list))])[:,0,:]) \n",
    "   \n",
    "   shape_dynamic_dataframe = pd.DataFrame(data_frame_list, columns =['Track ID', 't', 'z', 'y', 'x', 'Dividing', 'Number_Dividing',  'Radius', 'Volume', 'Eccentricity Comp First', 'Eccentricity Comp Second', 'Surface Area', 'Speed', 'Motion_Angle', 'Acceleration', 'Distance_Cell_mask', 'Radial_Angle', 'Cell_Axis_Mask'])\n",
    "   if len(global_shape_dynamic_dataframe) == 0:\n",
    "        global_shape_dynamic_dataframe = shape_dynamic_dataframe\n",
    "   else:\n",
    "        global_shape_dynamic_dataframe = pd.concat([global_shape_dynamic_dataframe, shape_dynamic_dataframe],ignore_index=True)\n",
    "\n",
    "global_shape_dynamic_dataframe = global_shape_dynamic_dataframe.set_index('Track ID')\n",
    "global_shape_dynamic_dataframe = global_shape_dynamic_dataframe.sort_values(by=['Track ID'])\n",
    "global_shape_dynamic_dataframe = global_shape_dynamic_dataframe.sort_values(by=['t'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_vectors = {}\n",
    "\n",
    "unique_track_ids = global_shape_dynamic_dataframe['Track ID'].unique()\n",
    "for track_id in unique_track_ids:\n",
    "    track_data = global_shape_dynamic_dataframe[global_shape_dynamic_dataframe['Track ID'] == track_id].sort_values(by='t')\n",
    "    \n",
    "    track_vector = track_data[['t', 'z', 'y', 'x', 'Dividing', 'Number_Dividing', 'Radius', 'Volume', 'Eccentricity Comp First', 'Eccentricity Comp Second', 'Surface Area', 'Speed', 'Motion_Angle', 'Acceleration', 'Distance_Cell_mask', 'Radial_Angle', 'Cell_Axis_Mask']]\n",
    "    \n",
    "    track_vector_list = track_vector.to_dict(orient='records')\n",
    "    \n",
    "    analysis_vectors[track_id] = track_vector_list\n",
    "\n",
    "vector_dicts = [analysis_vectors[key][0] for key in analysis_vectors]\n",
    "vector_array = np.array([list(vector.values()) for vector in vector_dicts])\n",
    "\n",
    "cosine_distance = pdist(vector_array, metric=cosine_similarity_without_tzyx)\n",
    "\n",
    "linkage_matrix = linkage(cosine_distance, method='average')\n",
    "\n",
    "threshold = 0.02  \n",
    "\n",
    "cluster_labels = fcluster(linkage_matrix, threshold, criterion='distance')\n",
    "    \n",
    "plot_vectors(vector_dicts, cluster_labels, base_dir)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naparienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
